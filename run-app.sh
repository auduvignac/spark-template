#!/usr/bin/env bash
set -e  # Stop on error

# =========================================================
# Script de lancement du cluster Spark + job
# =========================================================

BUILD=false

# === Parsing des arguments ===
while [[ $# -gt 0 ]]; do
  case "$1" in
    --build)
    BUILD=true
    ;;
    *)
    echo "âš ï¸  Argument inconnu : $1"
    ;;
  esac
  shift
done

# =========================================================
# Ã‰tape 0 : Compilation du projet Scala (si build)
# =========================================================
# Si l'utilisateur a demandÃ© une compilation
if [ "$BUILD" = true ]; then
  echo "ğŸ”§ Compilation du projet Scala..."

  # VÃ©rifie que sbt est installÃ©
  if ! command -v sbt &>/dev/null; then
      echo "âŒ Erreur : 'sbt' n'est pas installÃ© sur ta machine hÃ´te."
      echo "   âœ Installe-le avant de lancer ce script."
      exit 1
  fi

  # Nettoie et recompile le projet
  if sbt clean package; then
      echo "âœ… Compilation rÃ©ussie."
  else
      echo "âŒ Ã‰chec de la compilation Scala."
      exit 1
  fi
fi

# =========================================================
# Ã‰tape 1 : Lancement du cluster Spark via Docker
# =========================================================
echo "ğŸ§¹ Stopping existing Spark cluster (if any)..."
docker rm -f spark-submit spark-worker spark-master >/dev/null 2>&1 || true

echo "ğŸš€ Starting Spark cluster..."
docker-compose up -d

echo "â³ Waiting for Spark master to be ready..."
sleep 5

echo "âš™ï¸  Preparing spark-submit.sh inside container..."
docker exec spark-submit dos2unix /app/spark-submit.sh >/dev/null 2>&1 || true
docker exec spark-submit chmod +x /app/spark-submit.sh

echo "ğŸš€ Submitting Spark job..."

docker exec spark-submit /app/spark-submit.sh

echo ""
echo "ğŸ“œ Logs du conteneur spark-submit :"
docker logs spark-submit

echo ""
echo "âœ… Spark job completed successfully."